=======================================================
## Friday 1st December, 2017, after meeting with Holger
=======================================================

I have begun implementation of database cracking in Rust, which I chose
because of the need for the implementation to be high performance and
because my programming style lends itself to high level abstractions as
provided in rust vs the low level hacking that is idiomatic to C or C++.

I began by implementing the basic cracking algorithms crack_in_three and
crack_in_two, applied simply to Vec<i64>s. I moved through this implementation
using an unrigorous application of TDD. I wrote tests before implementing
code, but I've covered edge cases so far primarily by writing exhaustive
tests rather than really thinking about my code.

After implementing this minimal subset of cracking functionality, I updated
the Table struct, which previously contained just the size of the table and
its single column, to support multiple columns formatted using decomposed
storage. The columns are currently stored using a hashmap, such that the
mapping is column_name (String) -> column_data (Col). The Col is a struct
which contains the base column, the cracker column, which is created by the
cracking operators (currently only select), the cracker index (an AVL tree),
and a base index, which is an index used for tuple reconstruction. It is
used to maintain alignment knowledge about other columns of the table.

So far implementation has been pretty difficult, because the Rust compiler is
extremely picky. I'm getting used to it though I think, and as soon as this
ownership stuff becomes second nature the ball should really start rolling.

The literature I've read  has been mostly regarding graph databases, but
Idreos' cracking paper has been very helpful in implementation so far,
although the algorithms given in the paper didn't work for me, I gained a
sufficient understanding of how they are meant to work to reverse engineer
them from the properties and descriptions given in the paper.

The graph database literature has been interesting although I haven't of
course applied any of it yet. I've read the Ligra paper and skimmed the 
beginning of the Galuc thesis, as well as the cache aware graph processing
algorithms paper shown to me by Holger.

The next steps will be to benchmark what I've got right now using BFS and
possibly experiement with using N-ary storage isntead of decomposed storage, 
since adjacency lists do have only two columns.

========================================================================================
## Friday 1st December, 2017, preparing to change columns from fixed i64 -> set of types
========================================================================================

I've defined a tagged union, Field, which currently has I(i64) and F(f64), in
order to define float columns, which I'll need for benchmarking on algorithms
other than BFS. In my view, to hardcode i64 into the code makes it all a bit
pointless, because the overall system is impractical.

The steps here will be to find all the places where i64 is depended on and
replace them with Field and use rust's dynamic dispatch + compiler
optimisations to cleanly make the switch.

Furthermore, I'll need type checking around columns to ensure inserts are of the
correct type by each column, which will involve adding a "type" field to the Col
struct. I can here borrow the KDB idea of using a short integer as a type, or I
could simply use a char.

To sort out inclusivity, I'm going to keep my current method of using the
cracker index to store v,p pairs such that all elements before p and strictly
less than v. I'll use pattern matching to change the "adjusted_x" and
upper_bound-using variables for inclusivity handling. An issue would be
strings, but I have no need to crack on strings at the moment, so that's a
problem I'm definitely going to evaluate lazily.

=========================================================================
## Saturday 16th December, 2017, just started back on after finishing exams 
=========================================================================

Picking back up where I left off before being rudely interrupted by exams, I am
implementing BFS for my newly created, shuffled adjacency list, using cracking.
I'm looking to perform benchmarks for:
a) No optimisations at all (control)
b) Before-hand clustering on source nodes
c) Before-hand clustering + RLE on source nodes
d) On-line clustering on source nodes (using cracking)
e) On-line clustering + RLE on source nodes (using cracking)

(c) and (e) may require changes to my cracking implementation => time consuming.

I got some BFS code compiling and running pretty quickly actually, but I've
found another edge case in my cracking implementation that I need to patch
up, so I'll fix that tomorrow. I don't know what the problem is, but I'm going
to wait for tomorrow because it's 1:40am (On Sunday) and I need to sleep.

After I've got it working, edge cases and all, I'll want to find a way to do
benchmarks on the rust code, so that I have a fair way of comparing the
different optimisation methods.

=====================================================================
## Sunday 17th December, 2017, fixed failing edge case from yesterday
=====================================================================

I fixed the edge case and retained previous passing tests by making p_itr
catch up with p_low if it ever fell behind. I improved the test I added to
make sure cracking was working properly on the whole column, and indeed it's
fine. Will now check on the BFS implementation and make sure it's 100% halal.

=========================================================================
## Sunday 17th December, 2017, found and fixed many, many more edge cases
=========================================================================

Single values have caused a problem because they are messing with boundary
checking of indices. I think I have now resolved all the issues, but time will
tell.

I have also implemented the beginnings of a benchmarking system for this,
where first-class functions have been very useful. From a few runs with graphs
of 100 nodes, adaptive clustering is about twice as fast as unoptimised vector
scanning. I will do pre-clustering tomorrow, because for I'll want to include
in my measurement for it the time taken to sort the vector.

===============================================================
## Thursday 21st December, 2017, Got a preclustered BFS working
===============================================================

Did some some dirty while loop hack to get BFS working for the preclustering
variant of BFS. It works well with the benchmarks and I've checked it for
correctness on large inputs, so that's all good. In terms of benchmarks, for
a single run it performs slightly better than adaptive clustering for n=100
which I've tested it on. For tiny inputs (<10) unoptimised is best - for a
similar reason I imagine to why naive NLJ is best for joining tiny
relations - less overhead.

My current implementation for generating random connected graphs is
painfully slow for >200 nodes, so I'll need to fix that in order to get some
results for properly big inputs rather than the baby stuff I've got going at
the moment.

======================================================================
## Friday 22nd December, 2017, Sped up random connected graph creation
======================================================================

I made it go faster, so now 400 nodes is tolerable. I'm also noticing that as
the number of nodes increasing, the % difference between adaptive clustering
and preclustering is reducing, making me think that there may be a graph size
at which adaptive clustering outperforms preclustering even for a single run
of BFS. I won't be able to find out until it is much faster though because it
is probably a few thousand nodes or more.

To the benchmarking output I've also added a println! for how long it takes
to build the adjacency list used in the test.

I've now sped it up. The new implementation creates graphs which are far more
sparse than the earlier, slower implementation. It now deals the nodes into a
vector representing the order in which they will be added to the accumulating
graph, which is initialised as a single edge. Bidirectional edges are then added
according to this order until they have all been added. The resulting graph is
therefore definitely a tree, but every node can be reached from every other
node.

I have just now extracted some functions such that I can print a valid csv to
stdout containing data for runtime tests for each method (adaptive, unoptimised,
preclustering) for many different sparse graph sizes all at once. I will now
write a shell script + q script + J script for putting this data into a file,
reading into KDB, computing some analytics perhaps and creating an appropriate
graph. I'll probably consult Holger on which graphs I should be producing and
how I ought to analyse this data.

It's now at the stage where the benchmarking data I need will flow easily into
the Code/database_cracking/bms/ folder, and I just need to make some graphs
for it/compute some analytics.

I got some results for the node ranges:
  10-100 in tens
  100-1000 in  hundreds
  1000-10000 in thousands

0-10 nodes:
  Unoptimised is the fastest.
  Both unoptimised and preclustering are around 3x faster than adaptive.

Preclustering is always fastest for graphs >10 nodes.

10-100 nodes:
  Unoptimised is faster than adaptive clustering by 3x at 10 nodes, reducing
  to being <5% faster at 100 nodes.
  Preclustering goes from being about 3x faster at 10 nodes to being 2.5x
  faster at 100 nodes.

Adaptive is always faster than unoptimised for graphs >100 nodes.

200-900 nodes:
  Adaptive is 1.4x faster than unoptimised at 200 nodes, increasing to about
  2x at 900 nodes.
  Preclustering is 2x as fast as adaptive at 200 nodes, which reduces fairly
  slowly to being about 1.7x faster at 900 nodes.
  
1000-10000 nodes:
  Adaptive remains about 2x faster than unoptimised.
  Preclustering remains about 1.7x as fast as adaptive.

I'm sure there are more conclusions to draw from this data, but I'll need more
readings first, and I'll probably want to spend some time optimising all of
them as much as I possibly can.

=======================================================================================
## Sunday 24th December, 2017, Got a working and really nice graphing tool for the data
=======================================================================================

I've now set up a tool for plotting graphs using the collected benchmarking data with
the three methods being plotted on the same set of axes. It uses the lovely HTML5/JS
UI stuff and integrates into q and even works for multiple columns. Very nice. The
github repo is: https://github.com/komsit37/qchart

===============================================================================
## Tuesday 2nd January, 2018, Enabled optimisations on compiler, it's very fast
===============================================================================

After enabling optimisations and getting some more results, I discovered that there is a
very big performance difference between my stuff and the simpler methods. On debug-compiled
code I was doing fine, but for my adaptive techniques it is massively slower than both
unoptimised and preclustering technqiues by a lot. Preclustering runs on 10000 nodes faster
than adaptive runs on 2000 nodes. Unoptimised is barely slower than preclustering, the
overtake happens at aroud 500 nodes.

This pretty much means I am going to have to spend a LOT of time optimising the cracking
implementation and I'm probably also going to want to cut out a lot of wrapping and break
down all the overhead and reduce the implementation to act as a way of manipulating lists
of floats. This is now the next item on the agenda because this whole thing is just a joke
if nested for loops are a 10x performance improvement on the complicated mess I spew out.

==================================================================================
## Friday 5th January, 2018, optimised adaptive clustering, it's now very fast too
==================================================================================

This morning, adaptive clustering was something like 20x slower than both preclustering
and unoptimised BFS. Now is faster for graphs larger than 2000 nodes. I profiled the
performance of the BFS to see if I was being an idiot, no, that was fine. I found that
approximately 97% of the runtime of adaptive_bfs was inside the
adjacency_list.cracker_select_in_three call as expected.

Then I profiled cracker_select_in_three and discovered that about 74% of the runtime was
in tuple reconstruction at the end of the run of the function. This was due to the cloning
of the column in my initial naive implementation of tuple reconstruction. I fixed this
and reduced the share of time spent in tuple reconstruction to around 3% - a massive
improvement.

After making the change I had to check correctness, making sure the tests all still
passed and that everything was in order with a few manual tests as well just to satisfy
my paranoia, because I was quite worried that the performance improvements were simply a
result of work not being done. It seems all to be fine, but I might add some more tests
anyway.

Upon rerunning the benchmarks, I found that, as expected, for the smallest graphs,
naive nested loops are the fasted, for slightly larger graphs, preclustering and using
binary search is fastest, and for graphs larger than 2000 nodes, adaptive clustering is
the fastest. Very encouraging progress today.

=============================================================================
## Thursday 18th January, 2018, preclustering is far slower than it should be
=============================================================================

As it turns out, preclustering is about 10x slower than it should be, because
my implementation of bfs is awful. This is because the inbuilt binary search
function finds an undefined value one of the values which equal what you're
looking for, but because in the adjacency list there may be several edges from
some node src, I look for others by checking adjacent values in the list with
some loops. Apparently they are very terrible, because as I write this they
constitute 96% of the running time of preclustering_bfs. The two loops seem to
take pretty much the same amount of time. I am now working on a fix that will
hopefully hugely speed up preclustered_bfs.

=============================================================================
## Thursday 18th January, 2018, preclustering is far slower than it should be
=============================================================================

I've implemented preclustered BFS utlising RLE and I'm getting what I originally would
have expected - something that is faster than adaptive clustering by a pretty much
constant amount. The plotted lines are parallel and remain pretty much the same
distance apart. I'm now going to implement preclustering for the adaptive case and see
what that does.

My table data structure is not very flexible at the moment, and changing it will
require a lot of work and be pretty challenging due to the immense battle I'll need to
have with the rust compiler.

Found a new bug in cracking with single value selection - there is a problem with
fetching offsets from the cracker index - the incorrect offsets are being pulled and
so queries are not correct.

=====================================================================================
## Tuesday 30th January, 2018, Changed cracker index implementation for compression
=====================================================================================

We have been discussing quite often the prospect of compressive cracking. I came up with
an initial naive format, and in last Friday's meeting Holger and I discussed and
expanded to some better ideas. Eager vs lazy compression came up, and we also decided
that flattening lists + compaction was not really what we wanted. I've written some
notes also on squid regarding compression, hence the apparent reduction in writing.

Having spent some time thinking about the easiest way to get compression in that isn't
the naive method, I've got something quite similar that will also be easy to implement,
however, it will be even easier still if the cracker index is not an AVL tree, but just
an array. I have now implemented that change and also provided an abstraction for the
cracker index in its own module.

Using an array for the cracker index is also good because it means that we can get
faster lookup times for values around another. When compressing opportunistically (the
word I am giving for doing something not fully eagerly, but not really lazily either)
we are looking for consecutive values which are keys in the cracker index. Using an AVL
tree this is not trivial, but with an array it is, and moreover, it is very fast. One
of my initial concerns with looking for compression opportunities was that it would
require lots of cracker index probes in every scan, which I doubt would yield
acceptable performance.

==============================================================================
## Sunday 4th March, 2018, Updating implementation to support f64 column types
==============================================================================

I've had to spend some time upgrading the implementation in order to enable me to write
pagerank nicely, which has been a pain, but will hopefully pay off after I get it done.
At the moment you can currently add new columns of f64, get the f64 column, and insert
into f64 columns. This is implemented as having multiple hashmaps of columns, one map
per type. Some functions must still be updated and I need many, many more tests,
especially for insert.

I also did a little optimisation on ordinary cracking by enabling lazy "compression",
which involves no actual compression step, but when cracking for a single value, the
program checks if the cracker index contains consecutive values such that the indices
for the base column are known and can be returned in constant time. This saved a little
bit of runtime, but not loads.

===================================================================================
## Friday 9th March, 2018, Completed implementation update to support float columns
===================================================================================

I copied a lot of the tests for checking that integer-only cracking was okay, to make sure
that the updates I made to support float columns have gone through successfully. It seems
they have, which is great. Now that this is done, that should hopefully be the last change
I have to make that is not really related to the underlying implementation - I can focus
on experiments and optimisations. Off to see Holger now to discuss CSR exploitation and
how work is going to stonewall on this for a couple of weeks while I do exams.

============================================================================
## Monday 26th March, 2018, Finished exams. Implemented unoptimised pagerank
============================================================================

The implementation of the deal function currently has a big effect on the performance of
my graph generation functions. This might change in the future when I move to real world
graphs. I have sped it up significantly by removing the duplication polling, which was a
completely stupid idea to begin with, but I guess I was drunk or something.

It has also turned out that through a feat of unimaginable stupidity, I forogt that
actually float columns are not at all necessary for implementing pagerank. They might
come in handy simply because I can then throw them in as a column after compression,
since at that point the src column is indeed corresponding to nodes. Maybe other ideas
will come up and it will turn out not to have been a stupid waste of time. I hope so.

Just now (1AM, technically it's Tuesday) I have finished writing/debugging my initial
unoptimised implementation of pagerank, whcih I've tested using the example on the
wikipedia page. I am using damping, as suggested.

For termination, the wikipedia page suggests using an epsilon, however I found that for
this example, without damping, there is no steady state - it is cyclic and unstable.
Therefore I'm also using a max_iterations method as a backup behind the epsilon method.

I will also need to look into the cache-optimised pagerank paper that Holger sent me at
the start of this project, because it will hopefully give me insights into writing faster
pageranks for all of the methods.

I'm also needing to chase up Paul Kelly about CSR exploitation, because I don't really
know anything about it. I will perhaps also read something in one of the many papers I'm
printing off tomorrow. I should also ask other people who might know something.
