=======================================================
## Friday 1st December, 2017, after meeting with Holger
=======================================================

I have begun implementation of database cracking in Rust, which I chose
because of the need for the implementation to be high performance and
because my programming style lends itself to high level abstractions as
provided in rust vs the low level hacking that is idiomatic to C or C++.

I began by implementing the basic cracking algorithms crack_in_three and
crack_in_two, applied simply to Vec<i64>s. I moved through this implementation
using an unrigorous application of TDD. I wrote tests before implementing
code, but I've covered edge cases so far primarily by writing exhaustive
tests rather than really thinking about my code.

After implementing this minimal subset of cracking functionality, I updated
the Table struct, which previously contained just the size of the table and
its single column, to support multiple columns formatted using decomposed
storage. The columns are currently stored using a hashmap, such that the
mapping is column_name (String) -> column_data (Col). The Col is a struct
which contains the base column, the cracker column, which is created by the
cracking operators (currently only select), the cracker index (an AVL tree),
and a base index, which is an index used for tuple reconstruction. It is
used to maintain alignment knowledge about other columns of the table.

So far implementation has been pretty difficult, because the Rust compiler is
extremely picky. I'm getting used to it though I think, and as soon as this
ownership stuff becomes second nature the ball should really start rolling.

The literature I've read  has been mostly regarding graph databases, but
Idreos' cracking paper has been very helpful in implementation so far,
although the algorithms given in the paper didn't work for me, I gained a
sufficient understanding of how they are meant to work to reverse engineer
them from the properties and descriptions given in the paper.

The graph database literature has been interesting although I haven't of
course applied any of it yet. I've read the Ligra paper and skimmed the 
beginning of the Galuc thesis, as well as the cache aware graph processing
algorithms paper shown to me by Holger.

The next steps will be to benchmark what I've got right now using BFS and
possibly experiement with using N-ary storage isntead of decomposed storage, 
since adjacency lists do have only two columns.

========================================================================================
## Friday 1st December, 2017, preparing to change columns from fixed i64 -> set of types
========================================================================================

I've defined a tagged union, Field, which currently has I(i64) and F(f64), in
order to define float columns, which I'll need for benchmarking on algorithms
other than BFS. In my view, to hardcode i64 into the code makes it all a bit
pointless, because the overall system is impractical.

The steps here will be to find all the places where i64 is depended on and
replace them with Field and use rust's dynamic dispatch + compiler
optimisations to cleanly make the switch.

Furthermore, I'll need type checking around columns to ensure inserts are of the
correct type by each column, which will involve adding a "type" field to the Col
struct. I can here borrow the KDB idea of using a short integer as a type, or I
could simply use a char.

To sort out inclusivity, I'm going to keep my current method of using the
cracker index to store v,p pairs such that all elements before p and strictly
less than v. I'll use pattern matching to change the "adjusted_x" and
upper_bound-using variables for inclusivity handling. An issue would be
strings, but I have no need to crack on strings at the moment, so that's a
problem I'm definitely going to evaluate lazily.

=========================================================================
## Saturday 16th December, 2017, just started back on after finishing exams 
=========================================================================

Picking back up where I left off before being rudely interrupted by exams, I am
implementing BFS for my newly created, shuffled adjacency list, using cracking.
I'm looking to perform benchmarks for:
a) No optimisations at all (control)
b) Before-hand clustering on source nodes
c) Before-hand clustering + RLE on source nodes
d) On-line clustering on source nodes (using cracking)
e) On-line clustering + RLE on source nodes (using cracking)

(c) and (e) may require changes to my cracking implementation => time consuming.

I got some BFS code compiling and running pretty quickly actually, but I've
found another edge case in my cracking implementation that I need to patch
up, so I'll fix that tomorrow. I don't know what the problem is, but I'm going
to wait for tomorrow because it's 1:40am (On Sunday) and I need to sleep.

After I've got it working, edge cases and all, I'll want to find a way to do
benchmarks on the rust code, so that I have a fair way of comparing the
different optimisation methods.

=====================================================================
## Sunday 17th December, 2017, fixed failing edge case from yesterday
=====================================================================

I fixed the edge case and retained previous passing tests by making p_itr
catch up with p_low if it ever fell behind. I improved the test I added to
make sure cracking was working properly on the whole column, and indeed it's
fine. Will now check on the BFS implementation and make sure it's 100% halal.

=========================================================================
## Sunday 17th December, 2017, found and fixed many, many more edge cases
=========================================================================

Single values have caused a problem because they are messing with boundary
checking of indices. I think I have now resolved all the issues, but time will
tell.

I have also implemented the beginnings of a benchmarking system for this,
where first-class functions have been very useful. From a few runs with graphs
of 100 nodes, adaptive clustering is about twice as fast as unoptimised vector
scanning. I will do pre-clustering tomorrow, because for I'll want to include
in my measurement for it the time taken to sort the vector.

===============================================================
## Thursday 21st December, 2017, Got a preclustered BFS working
===============================================================

Did some some dirty while loop hack to get BFS working for the preclustering
variant of BFS. It works well with the benchmarks and I've checked it for
correctness on large inputs, so that's all good. In terms of benchmarks, for
a single run it performs slightly better than adaptive clustering for n=100
which I've tested it on. For tiny inputs (<10) unoptimised is best - for a
similar reason I imagine to why naive NLJ is best for joining tiny
relations - less overhead.

My current implementation for generating random connected graphs is
painfully slow for >200 nodes, so I'll need to fix that in order to get some
results for properly big inputs rather than the baby stuff I've got going at
the moment.

======================================================================
## Friday 22nd December, 2017, Sped up random connected graph creation
======================================================================

I made it go faster, so now 400 nodes is tolerable. I'm also noticing that as
the number of nodes increasing, the % difference between adaptive clustering
and preclustering is reducing, making me think that there may be a graph size
at which adaptive clustering outperforms preclustering even for a single run
of BFS. I won't be able to find out until it is much faster though because it
is probably a few thousand nodes or more.

To the benchmarking output I've also added a println! for how long it takes
to build the adjacency list used in the test.

I've now sped it up. The new implementation creates graphs which are far more
sparse than the earlier, slower implementation. It now deals the nodes into a
vector representing the order in which they will be added to the accumulating
graph, which is initialised as a single edge. Bidirectional edges are then added
according to this order until they have all been added. The resulting graph is
therefore definitely a tree, but every node can be reached from every other
node.

I have just now extracted some functions such that I can print a valid csv to
stdout containing data for runtime tests for each method (adaptive, unoptimised,
preclustering) for many different sparse graph sizes all at once. I will now
write a shell script + q script + J script for putting this data into a file,
reading into KDB, computing some analytics perhaps and creating an appropriate
graph. I'll probably consult Holger on which graphs I should be producing and
how I ought to analyse this data.

It's now at the stage where the benchmarking data I need will flow easily into
the Code/database_cracking/bms/ folder, and I just need to make some graphs
for it/compute some analytics.

I got some results for the node ranges:
  10-100 in tens
  100-1000 in  hundreds
  1000-10000 in thousands

0-10 nodes:
  Unoptimised is the fastest.
  Both unoptimised and preclustering are around 3x faster than adaptive.

Preclustering is always fastest for graphs >10 nodes.

10-100 nodes:
  Unoptimised is faster than adaptive clustering by 3x at 10 nodes, reducing
  to being <5% faster at 100 nodes.
  Preclustering goes from being about 3x faster at 10 nodes to being 2.5x
  faster at 100 nodes.

Adaptive is always faster than unoptimised for graphs >100 nodes.

200-900 nodes:
  Adaptive is 1.4x faster than unoptimised at 200 nodes, increasing to about
  2x at 900 nodes.
  Preclustering is 2x as fast as adaptive at 200 nodes, which reduces fairly
  slowly to being about 1.7x faster at 900 nodes.
  
1000-10000 nodes:
  Adaptive remains about 2x faster than unoptimised.
  Preclustering remains about 1.7x as fast as adaptive.

I'm sure there are more conclusions to draw from this data, but I'll need more
readings first, and I'll probably want to spend some time optimising all of
them as much as I possibly can.

=======================================================================================
## Sunday 24th December, 2017, Got a working and really nice graphing tool for the data
=======================================================================================

I've now set up a tool for plotting graphs using the collected benchmarking data with
the three methods being plotted on the same set of axes. It uses the lovely HTML5/JS
UI stuff and integrates into q and even works for multiple columns. Very nice. The
github repo is: https://github.com/komsit37/qchart

===============================================================================
## Tuesday 2nd January, 2018, Enabled optimisations on compiler, it's very fast
===============================================================================

After enabling optimisations and getting some more results, I discovered that there is a
very big performance difference between my stuff and the simpler methods. On debug-compiled
code I was doing fine, but for my adaptive techniques it is massively slower than both
unoptimised and preclustering technqiues by a lot. Preclustering runs on 10000 nodes faster
than adaptive runs on 2000 nodes. Unoptimised is barely slower than preclustering, the
overtake happens at aroud 500 nodes.

This pretty much means I am going to have to spend a LOT of time optimising the cracking
implementation and I'm probably also going to want to cut out a lot of wrapping and break
down all the overhead and reduce the implementation to act as a way of manipulating lists
of floats. This is now the next item on the agenda because this whole thing is just a joke
if nested for loops are a 10x performance improvement on the complicated mess I spew out.

==================================================================================
## Friday 5th January, 2018, optimised adaptive clustering, it's now very fast too
==================================================================================

This morning, adaptive clustering was something like 20x slower than both preclustering
and unoptimised BFS. Now is faster for graphs larger than 2000 nodes. I profiled the
performance of the BFS to see if I was being an idiot, no, that was fine. I found that
approximately 97% of the runtime of adaptive_bfs was inside the
adjacency_list.cracker_select_in_three call as expected.

Then I profiled cracker_select_in_three and discovered that about 74% of the runtime was
in tuple reconstruction at the end of the run of the function. This was due to the cloning
of the column in my initial naive implementation of tuple reconstruction. I fixed this
and reduced the share of time spent in tuple reconstruction to around 3% - a massive
improvement.

After making the change I had to check correctness, making sure the tests all still
passed and that everything was in order with a few manual tests as well just to satisfy
my paranoia, because I was quite worried that the performance improvements were simply a
result of work not being done. It seems all to be fine, but I might add some more tests
anyway.

Upon rerunning the benchmarks, I found that, as expected, for the smallest graphs,
naive nested loops are the fasted, for slightly larger graphs, preclustering and using
binary search is fastest, and for graphs larger than 2000 nodes, adaptive clustering is
the fastest. Very encouraging progress today.
