\chapter{Adaptive Compression}

\label{ch:adaptivecompression}

\section{Cracking}

In this chapter we examine ways of performing online compression of the adjacency list representing
the graph by modifying the existing cracking algorithms presented by Ideos' et al.. The background
subsection on cracking covers the terms we will use in this chapter to explain the modifications we
made.

\section{Compression}

In this section we demonstrate that online restructuring of an adjacency list into a CSR formatted 
adjacency matrix is feasible by using cracking, and discuss how this can be exploited to improve the
performance of the execution of graph traversal algorithms.

Our motivation for applying compression is to acheive a speed up by reducing the number of memory
accesses required in the execution of an algorithm. We will demonstrate in section
\ref{ss:compressionexploitation} how we exploit compression.

\subsection{Opportunities}

When compressing either the $src$ or $dst$ columns, we can gather compression information with
varying eagerness in the course of a cracking scan. We could reserve a decision on compression until
we know that an entire column fragment can be compressed, or we can make many small compressions in
the course of the scan of a column. When we compress only when identifying an entirely homogenous
column fragment, we call this "per-fragment" compression. When applying compression during the course
of the a scan of the column, this is "eager" compression. Within the space of possibilities for
eager compression, we have only explored run-length encoding (RLE) in this project.

\subsection{Per-fragment}

A per-fragment compression policy would be to compress only when entire column fragments are
known to be homogenous. After performing a scan, the cracker index is updated with the boundary
values for any created fragment(s). If two values are stored which are \texttt{minimally different},
then we can compress the column between those indices, which correspond to the boundary values of the
homogenous fragment.

We use the phrase \texttt{minimally different} to describe two values for which there exists no value
between them in the range of values that can be taken for their common type. For example, if we
consider the integers, the values 2 and 3 are minimally different, because there exists no integer
between these values. For a datatype such as a floating point number, this value will vary depending
on the accuracy with which the user wishes to cluster - it may be acceptable to the application that
the values 2.33334 and 2.33279 both be considered 2.33, however, unlike in the integer case, there is
information being lost during compression, which may not be acceptable to the user, which would prompt
them to use a greater granularity for the compression, or to not compress at all.

Compared to the RLE method, this is very easy to implement. One must simply check the boundaries of
newly created fragments and determine if any fragments can now be known to be homogenous.

\subsection{Run-length encoding (RLE)}

In the most eager case, we build and maintain information about all runs of consecutive nodes in the
cracker column of the adjacency list. This is done inside an array, $run\_lengths$.

The cracker column is scanned both front to back and back to front, therefore it would be preferable
that information be stored such that it can be applied in both scanning directions. For a given run of
consecutive values in the cracker column from index $i$ to index $j$ inclusive, the $run\_lengths$
array stores the value $1 + j - i$ at both indices $i$ and $j$, that is, the number of values in the
consecutive run. Therefore, when a pointer is moving from front to back, it can see the run length for
a given value, and a pointer moving in the opposite direction can see it also.

We also need to maintain the $run\_lengths$ array under the restructuring that takes place during
cracking to make it worthwhile, which requires that we be be careful in maintaining all of the
necessary invariants regarding the position of the two tightening edge pointers used during cracking.
This must also take account of the fact that the number of elements being swapped to an edge
pointer during an iteration may be different to the number of elements being swapped from the edge
pointer back onto the iteration pointer. Additionally, when making these swaps of runs, the
$run\_lengths$ array may have need to have its entries modified in order to retain consistency. There
are two potential approaches to swapping around runs of different lengths within the
$run\_lengths$ array.

The first is to swap the entire of the shorter run and modify entries of the $run\_lengths$ array
corresponding to the longer run to maintain consistency after the swap. This means that the longer
run is not fully swapped, so we have called it "underswapping". Underswapping causes the longer run
to get broken up.

The second approach is to swap the entire of the longer run, and pad the shorter run with more
elements. This requires the padded elements to have their runs checked and potentially modified, due
to the possibility that they are constituents of another run. Due to the fact that the shorter run is
swapped with more elements than are actually in that run (by padding), we call this "overswapping".
Overswapping Does not necessarily cause the break-up of runs, however it is more complex.

We now detail underswapping and overswapping, along with an evaluation of their relative performance
and a discussion thereof.

\subsubsection{Underswapping RLE}

Underswapping is the simpler of the two approaches, because it has fewer edge cases to consider. We
have only to amend the two pieces of the broken longer run before swapping all the values from the
smaller run across to the equally sized run just created from a piece of the longer run. This method
wastes the information we have acquired, but is fairly simple to implement.

\subsubsection{Overswapping RLE}

When overswapping, we swap the entire of the longer run, and pad the shorter run to length. The runs
within the padding must be amended to remain consistent, and if the padding contains partial runs,
then those runs must be amended outside the padding as well to remain consistent after the swap.
Additionally, if the padding causes the two swapped runs to overlap, then we don't have to swap all of
the values - a saving that requires us to also make updates into $run\_lengths$ to preserve
correctness.

\subsection{To compact or not to compact}

After identifying a homogenous section of the column, we have a choice in how we proceed in
compressing it. We can simply apply the knowledge that a contigious section is uniform, without 
making any physical changes to the data, or we can actually compact the uniform section, deleting
the duplicated elements. We will refer to these different modes as recognitive, for when we make the decision merely to recognise the homogenity of the section, and compactive, for when we make the
decision to compact.

\subsubsection{Recognitive}

After recognising a section of column which is uniform, if we intend to exploit this information, then
we need it stored somewhere.

If we are doing per-fragment compression, then it is sufficient to use the information already stored
in the cracker index, which we used in order to recognise the opportunity in the first place.

Otherwise, if we are applying a run-length encoding across the column, we need a separate structure to
hold the information about each of the runs.

The main advantage of this versus compaction is that it avoids the overhead of deleting arbitrary ranges from an array, thus avoiding unnecessary memcpy calls. However, this comes at the cost of
potential locality improvements and any associated exploitation.

\subsubsection{Compactive}

It is important to note that the columns are implemented as arrays, and as such all reside in
contigious memory, therefore when a range of contigiuos elements are deleted, the elements after
that range must be shifted back towards the front of the array. This memory shift is expensive,
and the cost increases with the amount of data that must be copied over.

It can be said that compaction saves memory, however if it was crucial to save memory, then cracking
would not be an appropriate technique anyway, so we do not consider it an important benefit.

Overall this method appears to be more expensive without strong benefits to make it worthwhile in
using. We have implemented and evaluated it nonetheless to see if our prediction is correct.
